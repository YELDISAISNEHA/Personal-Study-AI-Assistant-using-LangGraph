{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42847314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages, AnyMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bb606d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_task: str\n",
    "\n",
    "def detect_task(state: State) -> State:\n",
    "    user_input = state[\"messages\"][-1].content\n",
    "    prompt = \"\"\"\n",
    "    You are an task identifier\n",
    "    Classify the request of user_input in to one of the following tasks:\n",
    "    - summarize\n",
    "    - study plan\n",
    "    - Question & Answers\n",
    "    - quiz\n",
    "\n",
    "    Request: {user_input}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    user_task = response.content.strip().lower()\n",
    "    if \"summarize\" in user_task:\n",
    "        user_task = \"summarize\"\n",
    "    elif \"plan\" in user_task:\n",
    "        user_task = \"study_plan\"\n",
    "    elif \"question\" in user_task or \"answer\" in user_task or \"q&a\" in user_task:\n",
    "        user_task = \"question&answer\"\n",
    "    elif \"quiz\" in user_task:\n",
    "        user_task = \"quiz\"\n",
    "    else:\n",
    "        user_task = \"question&answer\"\n",
    "    return {**state, \"user_task\": user_task}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8c2d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(state: State) -> State:\n",
    "    text = state[\"messages\"][-1].content\n",
    "    response = llm.invoke(f\"Summarize this text for Study: {text}\")\n",
    "    return {**state, \"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "def study_plan(state: State) -> State:\n",
    "    topic = state[\"messages\"][-1].content\n",
    "    response = llm.invoke(f\"Create a weekly plan on {topic}\")\n",
    "    return {**state, \"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "def q_a(state: State) -> State:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    response = llm.invoke(query)\n",
    "    return {**state, \"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "def quiz(state: State) -> State:\n",
    "    topic = state[\"messages\"][-1].content\n",
    "    response = llm.invoke(f\"Create a quiz with 5 questions on {topic}\")\n",
    "    return {**state, \"messages\": state[\"messages\"] + [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a902e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(\"detectTask_node\", detect_task)\n",
    "builder.add_node(\"summarize_node\", summarize)\n",
    "builder.add_node(\"studyPlan_node\", study_plan)\n",
    "builder.add_node(\"Q&A_node\", q_a)\n",
    "builder.add_node(\"quiz_node\", quiz)\n",
    "\n",
    "builder.add_edge(START, \"detectTask_node\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"detectTask_node\",\n",
    "    lambda state: state[\"user_task\"],\n",
    "    {\n",
    "        \"summarize\": \"summarize_node\",\n",
    "        \"study_plan\": \"studyPlan_node\",\n",
    "        \"question&answer\": \"Q&A_node\",\n",
    "        \"quiz\": \"quiz_node\",\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"summarize_node\", END)\n",
    "builder.add_edge(\"studyPlan_node\", END)\n",
    "builder.add_edge(\"Q&A_node\", END)\n",
    "builder.add_edge(\"quiz_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09e15249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: LangGraph is a framework built on top of LangChain that allows you to create **stateful, multi-actor applications using graphs**. Think of it as a way to orchestrate complex conversational flows with multiple agents or functions working together in a structured, defined manner.\n",
      "\n",
      "Here's a breakdown of the key aspects:\n",
      "\n",
      "*   **Stateful:** LangGraph manages the state of your application throughout the conversation. This means it remembers previous interactions and uses that information to guide future actions.\n",
      "\n",
      "*   **Multi-Actor:**  It enables you to incorporate multiple actors (like LLMs, tools, functions, or even human input) into your application. Each actor can perform a specific task.\n",
      "\n",
      "*   **Graphs:**  The core of LangGraph is its use of a graph structure to define the flow of your application.  Nodes in the graph represent actors or steps, and edges represent the transitions between them. This provides a clear and visual way to understand and manage complex conversational flows.\n",
      "\n",
      "**Key benefits of using LangGraph:**\n",
      "\n",
      "*   **Structure and Organization:** Provides a framework for organizing complex conversational workflows, making them easier to build, understand, and maintain.\n",
      "*   **Flexibility:** Allows for a wide range of application types, from simple chatbots to complex AI assistants.\n",
      "*   **State Management:** Simplifies state management, ensuring that your application remembers previous interactions.\n",
      "*   **Multi-Agent Orchestration:** Enables you to easily combine the capabilities of multiple agents or tools.\n",
      "*   **Debugging and Visualization:** The graph structure makes it easier to debug and visualize the flow of your application.\n",
      "\n",
      "In essence, LangGraph is a powerful tool for building complex, stateful, and multi-actor conversational AI applications by using graphs to define the flow of interactions. It allows you to orchestrate multiple agents and functions in a structured and organized manner.\n",
      "Bot: LangGraph is a LangChain-based framework for building complex, stateful, multi-actor conversational AI applications. It uses a graph structure to define the flow of interactions between different actors (LLMs, tools, functions, etc.), allowing for structured and organized orchestration of complex conversational workflows. Key benefits include improved organization, flexibility, state management, multi-agent orchestration, and easier debugging and visualization.\n",
      "Bot: Please provide the text you want me to summarize and give a sample code for. I need the content to be able to help you.\n",
      "\n",
      "For example, you can give me something like this:\n",
      "\n",
      "\"**Text:** Python is a versatile programming language known for its readability and ease of use. It supports multiple programming paradigms, including object-oriented, imperative, and functional programming. Python is widely used in web development, data science, machine learning, scripting, and automation. Its large standard library and extensive ecosystem of third-party packages make it suitable for a wide range of tasks.\"\n",
      "\n",
      "Then I can provide a summary and a sample code snippet.\n",
      "Bot: Please provide the text you want me to summarize for study. I need the text to understand what you want me to summarize.\n",
      "\n",
      "Once you provide the text, I will:\n",
      "\n",
      "1.  **Summarize the key concepts and ideas** in a way that is suitable for studying.\n",
      "2.  **Provide a simple `lagGraph` code example** (in Python using matplotlib, as that's the most common context) *assuming the text discusses time series data and the usefulness of lag plots*.  If the text is about something else, I'll adjust the code accordingly or tell you that a lag plot is not applicable.\n",
      "\n",
      "**Example of how to provide the text:**\n",
      "\n",
      "\"I want you to summarize this:  'Time series data often exhibits autocorrelation, meaning that past values influence future values. A lag plot is a scatter plot that helps visualize this autocorrelation. It plots the value at time t against the value at time t-k, where k is the lag. Patterns in the lag plot indicate autocorrelation. For example, a strong linear relationship suggests a high degree of autocorrelation.'\"\n",
      "\n",
      "Then I can give you a summary and code.\n",
      "Bot: Please provide the text you would like me to summarize for study. I need the text to be able to help you.\n",
      "Bot: Please provide the text you would like me to summarize for study. I need the text to be able to give you a good summary!\n",
      "Bot: Please provide the text you would like me to summarize for study. I need the text to be able to give you a useful summary.\n",
      "Bot: Please provide the text you would like me to summarize for your study of \"Escape.\" I need the text to be able to help you. Once you provide the text, I will summarize it with a focus on themes related to escape, such as:\n",
      "\n",
      "*   **Motivations for escaping:** What are the characters trying to get away from (oppression, danger, boredom, etc.)?\n",
      "*   **Methods of escape:** How do they attempt to escape (physical flight, mental detachment, rebellion, etc.)?\n",
      "*   **Consequences of escape:** What happens after the escape (success, failure, new challenges, etc.)?\n",
      "*   **Symbolism of escape:** What does the act of escaping represent in the context of the story?\n",
      "GoodBye\n"
     ]
    }
   ],
   "source": [
    "state = None\n",
    "while True:\n",
    "    in_message = input(\"You: \")\n",
    "    if in_message.lower() in {\"quit\",\"exit\"}:\n",
    "        print(\"GoodBye\")\n",
    "        break\n",
    "    if state is None:\n",
    "        state: State = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": in_message}]\n",
    "        }\n",
    "    else:\n",
    "        state[\"messages\"].append({\"role\": \"user\", \"content\": in_message})\n",
    "\n",
    "    state = graph.invoke(state)\n",
    "    print(\"Bot:\", state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e19ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
